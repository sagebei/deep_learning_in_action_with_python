{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    \"今天外面天气很好\",\n",
    "    \"人工智能正在改变世界\",\n",
    "    \"我们明天早上一起去图书馆学习\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\BEIZHO~1\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.783 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['今天 外面 天气 很 好', '人工智能 正在 改变 世界', '我们 明天 早上 一起 去 图书馆 学习']\n"
     ]
    }
   ],
   "source": [
    "import jieba\n",
    "new_sentences = []\n",
    "for sentence in sentences:\n",
    "    # 对句子进行分词处理\n",
    "    segments = jieba.cut(sentence)\n",
    "    # 将句子中的每一个词汇用空格分来\n",
    "    new_sentence = \" \".join(segments)\n",
    "    # 将处理好的句子存储到列表中\n",
    "    new_sentences.append(new_sentence)\n",
    "print(new_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['今天 外面 天气 很 好', '人工智能 正在 改变 世界', '我们 明天 早上 一起 去 图书馆 学习']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'今天': 1, '外面': 2, '天气': 3, '很': 4, '好': 5, '人工智能': 6, '正在': 7, '改变': 8, '世界': 9, '我们': 10, '明天': 11, '早上': 12, '一起': 13, '去': 14, '图书馆': 15, '学习': 16}\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "tokenizer = Tokenizer(num_words=20)\n",
    "tokenizer.fit_on_texts(new_sentences)\n",
    "word_index = tokenizer.word_index\n",
    "print(word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 2, 3, 4, 5], [6, 7, 8, 9], [10, 11, 12, 13, 14, 15, 16]]\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import text_to_word_sequence\n",
    "sequences = tokenizer.texts_to_sequences(new_sentences)\n",
    "print(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one_hot_result = tokenizer.texts_to_matrix(samples, mode='binary')\n",
    "# print(one_hot_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0  1  2  3  4  5]\n",
      " [ 0  0  0  6  7  8  9]\n",
      " [10 11 12 13 14 15 16]]\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "padded_sequences = pad_sequences(sequences, padding='pre')\n",
    "print(padded_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  2  3  4  5  0  0]\n",
      " [ 6  7  8  9  0  0  0]\n",
      " [10 11 12 13 14 15 16]]\n"
     ]
    }
   ],
   "source": [
    "padded_sequences = pad_sequences(sequences, padding='post')\n",
    "print(padded_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  1  2  3  4  5]\n",
      " [ 0  0  6  7  8  9]\n",
      " [11 12 13 14 15 16]]\n"
     ]
    }
   ],
   "source": [
    "padded_sequences = pad_sequences(sequences, \n",
    "                                 padding='pre', \n",
    "                                 truncating='pre',\n",
    "                                 maxlen=6)\n",
    "print(padded_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 7, 3)              51        \n",
      "=================================================================\n",
      "Total params: 51\n",
      "Trainable params: 51\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "padded_sequences = pad_sequences(sequences, padding='pre')\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding\n",
    "model = Sequential()\n",
    "embedding = Embedding(input_dim=17,\n",
    "                      input_length=7,\n",
    "                      output_dim=3)\n",
    "model.add(embedding)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  1,  2,  3,  4,  5],\n",
       "       [ 0,  0,  0,  6,  7,  8,  9],\n",
       "       [10, 11, 12, 13, 14, 15, 16]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[-0.02805706,  0.02496606, -0.02966118],\n",
      "       [-0.04563084, -0.01646264, -0.02802988],\n",
      "       [ 0.02386883, -0.01998019, -0.00714093],\n",
      "       [ 0.01394485,  0.02984795,  0.03769021],\n",
      "       [-0.04217581,  0.0048572 ,  0.03675225],\n",
      "       [ 0.00317006, -0.01415241, -0.02957951],\n",
      "       [-0.00254823, -0.03221738,  0.02868478],\n",
      "       [ 0.00424597,  0.02475877,  0.03217186],\n",
      "       [ 0.04807809,  0.00277642, -0.0001649 ],\n",
      "       [ 0.04473079, -0.02043191, -0.04517198],\n",
      "       [ 0.03993343,  0.03947297,  0.03220726],\n",
      "       [-0.04395154,  0.03991366, -0.04074151],\n",
      "       [ 0.01765602, -0.03504368,  0.04820906],\n",
      "       [ 0.00785128, -0.04658672, -0.00375912],\n",
      "       [ 0.0246125 ,  0.04838799,  0.02064878],\n",
      "       [ 0.02953463,  0.00808661, -0.02835951],\n",
      "       [ 0.03881926, -0.0053608 , -0.03023617]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "print(embedding.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(padded_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-0.02805706,  0.02496606, -0.02966118],\n",
       "        [-0.02805706,  0.02496606, -0.02966118],\n",
       "        [-0.04563084, -0.01646264, -0.02802988],\n",
       "        [ 0.02386883, -0.01998019, -0.00714093],\n",
       "        [ 0.01394485,  0.02984795,  0.03769021],\n",
       "        [-0.04217581,  0.0048572 ,  0.03675225],\n",
       "        [ 0.00317006, -0.01415241, -0.02957951]],\n",
       "\n",
       "       [[-0.02805706,  0.02496606, -0.02966118],\n",
       "        [-0.02805706,  0.02496606, -0.02966118],\n",
       "        [-0.02805706,  0.02496606, -0.02966118],\n",
       "        [-0.00254823, -0.03221738,  0.02868478],\n",
       "        [ 0.00424597,  0.02475877,  0.03217186],\n",
       "        [ 0.04807809,  0.00277642, -0.0001649 ],\n",
       "        [ 0.04473079, -0.02043191, -0.04517198]],\n",
       "\n",
       "       [[ 0.03993343,  0.03947297,  0.03220726],\n",
       "        [-0.04395154,  0.03991366, -0.04074151],\n",
       "        [ 0.01765602, -0.03504368,  0.04820906],\n",
       "        [ 0.00785128, -0.04658672, -0.00375912],\n",
       "        [ 0.0246125 ,  0.04838799,  0.02064878],\n",
       "        [ 0.02953463,  0.00808661, -0.02835951],\n",
       "        [ 0.03881926, -0.0053608 , -0.03023617]]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
