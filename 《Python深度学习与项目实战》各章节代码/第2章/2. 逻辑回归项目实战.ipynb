{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cce4c8a2",
   "metadata": {},
   "source": [
    "### 1. 数据集的加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f80c59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dataset = pd.read_csv('dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707b0282",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将性别特征转化为数字\n",
    "dataset['Sex'] = dataset['Sex'].astype('category').cat.codes\n",
    "# 将年龄特征缺失的样本使用年龄的均值替换\n",
    "dataset['Age'] = dataset['Age'].fillna(dataset['Age'].mean())\n",
    "# 所有样本的特征\n",
    "X = dataset[['Pclass','Sex','Fare','Age']].values\n",
    "# 所有样本的标签\n",
    "y = dataset['Survived'].values\n",
    "# 将数据集所有样本的特征进行标准化\n",
    "mean = X.mean(axis=0)\n",
    "std = X.std(axis=0)\n",
    "X = (X - mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42645cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# 将数据集分为训练集与测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "# 训练集样本的个数\n",
    "n_train = X_train.shape[0]\n",
    "# 每个样本中的特征值的个数\n",
    "n_features = X_train.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9020ea",
   "metadata": {},
   "source": [
    "### 2. 模型的构建与训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1b2a496",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def sigmoid(x):\n",
    "    y = 1 / (1 + np.exp(-x))\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acbdb97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对逻辑回归模型的参数进行随机初始化\n",
    "w = np.random.rand(n_features)\n",
    "b = 1.1\n",
    "# 构建逻辑回归模型\n",
    "def model(x):\n",
    "    z = w.dot(x) + b\n",
    "    y_hat = sigmoid(z)\n",
    "    return y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424c3204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 指定模型进行训练的次数\n",
    "epochs = 10000\n",
    "# 指定学习率的值\n",
    "lr = 0.01\n",
    "# 使用梯度下降算法对逻辑回归模型进行训练\n",
    "for epoch in range(epochs):\n",
    "    sum_w = np.zeros(n_features)\n",
    "    sum_b = 0.0\n",
    "    for i in range(n_train):\n",
    "        xi = X_train[i]\n",
    "        yi_hat = model(xi)\n",
    "        yi = y_train[i]\n",
    "        sum_w += (yi_hat - yi) * xi\n",
    "        sum_b += (yi_hat - yi)\n",
    "    # 计算出权重参数对损失函数的梯度值\n",
    "    grad_w = (1 / n_train) * sum_w\n",
    "    # 计算出偏移项对损失函数的梯度值\n",
    "    grad_b = (1 / n_train) * sum_b\n",
    "    w = w - lr * grad_w\n",
    "    b = b - lr * grad_b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a439c730",
   "metadata": {},
   "source": [
    "### 3. 模型的评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2651da06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X):\n",
    "    predictions = []\n",
    "    n_samples = X.shape[0]\n",
    "    for i in range(n_samples):\n",
    "        xi = X[i]\n",
    "        yi_hat = model(xi)\n",
    "        if yi_hat < 0.5:\n",
    "            # 当模型的预测值小于0.5时，预测为第一类\n",
    "            predictions.append(0)\n",
    "        else:\n",
    "            # 放模型的预测值大于0.5时，预测为第二类\n",
    "            predictions.append(1)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea70450",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算逻辑回归模型对数据集中的样本预测准确度\n",
    "def get_accuracy(X, y):\n",
    "    n_samples = X.shape[0]\n",
    "    predictions = predict(X)\n",
    "    loss = 0\n",
    "    for i in range(n_samples):\n",
    "        if y[i] != predictions[i]:\n",
    "            loss += 1 \n",
    "    accuracy = (n_samples - loss) / n_samples\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928bc98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracy = get_accuracy(X_train, y_train)\n",
    "test_accuracy = get_accuracy(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1cdfcfb",
   "metadata": {},
   "source": [
    "### 3. 使用矩阵的方式加速模型的训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65eba356",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.random.rand(n_features)\n",
    "b = 0\n",
    "def model(X):\n",
    "    z = w.dot(X.T) + b\n",
    "    y_hat = sigmoid(z)\n",
    "    return y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9d0f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10000\n",
    "lr = 0.01\n",
    "for epoch in range(epochs):\n",
    "    sum_w = np.zeros(n_features)\n",
    "    sum_b = 0.0\n",
    "    # 使用模型一次计算出全部训练集样本的预测结果\n",
    "    y_hat = model(X_train)\n",
    "    # 计算模型参数梯度值\n",
    "    sum_w = np.dot((y_hat - y_train), X_train)\n",
    "    sum_b = np.sum(y_hat - y_train)\n",
    "    grad_w = (1 / n_train) * sum_w\n",
    "    grad_b = (1 / n_train) * sum_b\n",
    "    # 使用梯度下降算法更新模型参数\n",
    "    w = w - lr * grad_w\n",
    "    b = b - lr * grad_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a79737",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracy = get_accuracy(X_train, y_train)\n",
    "test_accuracy = get_accuracy(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
