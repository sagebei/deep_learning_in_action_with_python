{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b49c3aed",
   "metadata": {},
   "source": [
    "### 1. MNIST数据集的加载与预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75a1788",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "\n",
    "# 加载MNIST数据集\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# 定义独热编码函数\n",
    "def one_hot_encoding(labels, n_classes):\n",
    "    result = np.eye(n_classes)[labels]\n",
    "    return result\n",
    "\n",
    "# n_train与n_test分别表示训练集与测试集样本个数\n",
    "n_train = X_train.shape[0] \n",
    "n_test = X_test.shape[0] \n",
    "# n_classes表示MNIST数据集的标签种类\n",
    "n_classes = 10\n",
    "# flatten_size为图片的像素总数，即扁平化后图片数组的长度\n",
    "flatten_size = 28 * 28\n",
    "# 将训练集图片进行归一化：将图片中的每一个像素值转变为0~1之间\n",
    "X_train = X_train / 255\n",
    "# 对图片（特征）进行扁平化处理\n",
    "X_train = X_train.reshape((n_train, flatten_size))\n",
    "# 对标签进行独热编码\n",
    "y_train = one_hot_encoding(y_train, n_classes)\n",
    "#对测试集数据进行同样的操作\n",
    "X_test = X_test / 255\n",
    "X_test = X_test.reshape((n_test, flatten_size))\n",
    "y_test = one_hot_encoding(y_test, n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3402bcbf",
   "metadata": {},
   "source": [
    "### 2. Softmax分类器模型的构建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468ecf9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化模型参数\n",
    "W = np.random.rand(10, 784)\n",
    "b = np.zeros((10, 1))\n",
    "# 构建Softmax多分类器模型\n",
    "def model(X):\n",
    "    n_samples = X.shape[0]\n",
    "    Z = W.dot(X.T) + b\n",
    "    exp_Z = np.exp(Z)\n",
    "    sum_E = np.sum(exp_Z, axis=0)\n",
    "    y_hat = exp_Z / sum_E\n",
    "    return y_hat.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f076fb6",
   "metadata": {},
   "source": [
    "### 3. Softmax模型的训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78f8ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 指定模型的次数与学习率\n",
    "epochs = 2000\n",
    "lr = 0.05\n",
    "# 使用梯度下降算法对模型进行训练\n",
    "for epoch in range(epochs):\n",
    "    sum_w = np.zeros_like(W)\n",
    "    sum_b = np.zeros_like(b)\n",
    "    # 使用Softmax多分类器进行预测\n",
    "    y_hat = model(X_train)\n",
    "    # 计算模型参数的梯度值\n",
    "    sum_w = np.dot((y_hat - y_train).T, X_train)\n",
    "    sum_b = np.sum((y_hat - y_train), axis=0).reshape(-1, 1)\n",
    "    grad_w = (1 / n_train) * sum_w\n",
    "    grad_b = (1 / n_train) * sum_b\n",
    "    # 使用梯度下降算法更新模型参数\n",
    "    W = W - lr * grad_w\n",
    "    b = b - lr * grad_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517e3eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuarcy(X, y):\n",
    "    # 数据集中样本的个数\n",
    "    n_samples = X.shape[0]\n",
    "    y_hat = model(X)\n",
    "    # 使用Softmax多分类器预测的样本类别\n",
    "    y_hat = np.argmax(y_hat, axis=1)\n",
    "    # 样本的实际类别（标签值）\n",
    "    y = np.argmax(y, axis=1)\n",
    "    count = 0\n",
    "    for i in range(len(y_hat)):\n",
    "        if(y[i] == y_hat[i]):\n",
    "            count += 1\n",
    "    accuracy = count / n_samples\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38045e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracy = get_accuarcy(X_train, y_train)\n",
    "test_accuracy = get_accuarcy(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
